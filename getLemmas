#!/bin/bash
# get entity data of first 2000 lexemes (or any other sequence)
START=${1:-1}
END=${2:-3060}
for i in $(eval echo "{$START..$END..50}"); do
    ids="L$i"
    for ((j=1;j<50;j++)); do
        ids+="|L$((i+j))"
    done
    curl \
        --silent \
        --data-urlencode action=wbgetentities \
        --data-urlencode format=json \
        --data-urlencode formatversion=2 \
        --data-urlencode ids="$ids" \
        --data-urlencode props="labels|claims" \
        https://www.wikidata.org/w/api.php | \
        jq -c '.entities[]|select(.missing|not)'
    sleep 1
done
